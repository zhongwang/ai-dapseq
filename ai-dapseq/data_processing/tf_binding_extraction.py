import os
import pandas as pd
import pyBigWig
import numpy as np

# Placeholder paths - replace with actual file paths and list of bigwig files
PROMOTER_REGIONS_FILE = "./promoter_regions.tsv"
DAPSEQ_BIGWIG_DIR = "../path/to/dapseq_bigwigs" # Directory containing all TF bigwig files
OUTPUT_DIR = "./tf_binding_profiles" # Output directory for processed profiles

# Assume bigwig file names are like TF_NAME.bigWig
# This list should contain the base names of all TF bigwig files (e.g., ['TF1.bigWig', 'TF2.bigWig'])
# Or better, read this list from the directory
# Example:
# TF_BIGWIG_FILES = [f for f in os.listdir(DAPSEQ_BIGWIG_DIR) if f.endswith(".bigWig")]
# For now, use a placeholder list:
TF_BIGWIG_FILES = ["TF1.bigWig", "TF2.bigWig", "TF3.bigWig"] # Replace with actual list

def load_promoter_regions(promoter_regions_path):
    """
    Loads promoter regions and their sequences from a TSV file.
    Returns a pandas DataFrame.
    """
    print(f"Loading promoter regions from {promoter_regions_path}")
    try:
        # Assuming the TSV has 'gene_id' and 'sequence' columns
        promoter_df = pd.read_csv(promoter_regions_path, sep='\t')
        print(f"Loaded {len(promoter_df)} promoter regions.")
        return promoter_df
    except Exception as e:
        print(f"Error loading promoter regions file: {e}")
        return None

def extract_tf_binding_signals(promoter_df, bigwig_dir, tf_bigwig_files):
    """
    Extracts TF binding signals for each promoter from bigWig files.
    Returns a dictionary mapping gene_id to a matrix (num_tfs x promoter_length).
    """
    tf_binding_data = {}
    num_tfs = len(tf_bigwig_files)
    # Assuming all promoters have the same length (2501bp) as defined in the plan
    # This needs to be verified or handled dynamically if lengths vary.
    # For now, assume a fixed length based on the plan.
    promoter_length = 2501 # Based on -2000 to +500

    print(f"Extracting binding signals for {num_tfs} TFs...")

    # It's more efficient to open each bigwig file once and iterate through genes
    bigwig_handles = {}
    try:
        for tf_file in tf_bigwig_files:
            tf_name = os.path.splitext(tf_file)[0] # Use filename without extension as TF name
            bigwig_path = os.path.join(bigwig_dir, tf_file)
            try:
                bw = pyBigWig.open(bigwig_path)
                bigwig_handles[tf_name] = bw
                print(f"Opened bigWig file: {tf_file}")
            except Exception as e:
                print(f"Warning: Could not open bigWig file {bigwig_path}: {e}. Skipping this TF.")
                bigwig_handles[tf_name] = None # Store None to indicate failure

        # Iterate through each gene promoter
        for index, row in promoter_df.iterrows():
            gene_id = row['gene_id']
            # Need chromosome, start, end, strand for each gene.
            # The current promoter_regions.tsv only has gene_id and sequence.
            # This script needs the genomic coordinates.
            # The output of promoter_extraction.py should ideally include these.
            # Let's assume for now we can get these from somewhere, or modify the previous script output.
            # For a proper implementation, the promoter_regions.tsv should contain:
            # gene_id | chromosome | start | end | strand | sequence
            # Let's add placeholder logic assuming we have these:
            # chrom = row['chromosome'] # Placeholder
            # start_coord = row['start'] # Placeholder (genomic start of promoter)
            # end_coord = row['end']     # Placeholder (genomic end of promoter)
            # strand = row['strand']     # Placeholder

            # Since the previous script didn't output coords, let's assume we need to re-parse GFF3
            # or load a more detailed gene_info structure.
            # For now, let's use dummy coordinates or assume they are available.
            # This highlights a dependency on the exact output format of the previous step.

            # *** REFINEMENT NEEDED HERE ***
            # The promoter_regions.tsv should contain the genomic coordinates.
            # Let's assume the previous script was modified to output:
            # gene_id | chromosome | start | end | strand | sequence
            # And load it accordingly:
            # promoter_df = pd.read_csv(promoter_regions_path, sep='\t') # Assuming updated format

            # For the current script structure, let's assume we have a way to get coords for each gene_id
            # Perhaps load the gene_info dictionary generated by parse_gff3 in the previous script?
            # Or modify the previous script to save gene_info as a pickle or JSON?

            # Let's proceed assuming we have access to the gene_info dictionary from the previous step
            # or a similar structure containing (chromosome, start_codon_pos, strand) for each gene_id.
            # This requires coordinating the output/input between scripts.

            # Assuming gene_info is available (e.g., loaded from a file saved by the previous script)
            # Example structure: gene_info = {'gene_id_1': ('chr1', 1000, '+'), ...}
            # For now, let's use dummy data or assume gene_info is passed/loaded.
            # This is a critical dependency that needs to be resolved in the workflow.

            # Let's add a placeholder for loading gene_info or getting coordinates
            # For demonstration, let's assume we have a function get_gene_coordinates(gene_id)
            # that returns (chromosome, promoter_start, promoter_end, strand) in 1-based genomic coords.
            # This function would ideally load data saved by promoter_extraction.py

            # Placeholder function - REPLACE WITH ACTUAL COORDINATE LOADING
            def get_gene_coordinates(gene_id):
                 # This function needs to load/access the data generated in promoter_extraction.py
                 # For now, returning dummy data or raising an error
                 # print(f"Error: Coordinate lookup not implemented for {gene_id}")
                 # return None, None, None, None
                 # To make this runnable for testing, let's return dummy data for a known gene ID
                 # This is NOT a real solution.
                 if gene_id == "AT1G01010": # Example gene ID
                     # Dummy coordinates for testing (chr1, 1-based start/end, strand)
                     return "chr1", 3631, 6131, "+" # Example promoter region for AT1G01010
                 # Add more dummy data or load from a file
                 return None, None, None, None # Indicate not found


            chrom, promoter_start_1based, promoter_end_1based, strand = get_gene_coordinates(gene_id)

            if chrom is None:
                 print(f"Warning: Could not get coordinates for gene {gene_id}. Skipping.")
                 continue

            # Convert 1-based genomic coordinates to 0-based for pyBigWig
            promoter_start_0based = promoter_start_1based - 1
            promoter_end_0based = promoter_end_1based - 1 # pyBigWig uses 0-based end-inclusive? No, pyBigWig uses 0-based, end-exclusive for values() and stats()

            # pyBigWig.values(chrom, start, end) extracts values from start (0-based, inclusive)
            # to end (0-based, exclusive).
            # So for a region 1-100 (1-based), which is 0-99 (0-based), we need values(chrom, 0, 100).
            # Our 1-based promoter_start_1based to promoter_end_1based needs to be
            # promoter_start_1based - 1 (0-based start) to promoter_end_1based (0-based end exclusive)

            promoter_start_0based = promoter_start_1based - 1
            promoter_end_0based_exclusive = promoter_end_1based # pyBigWig end is exclusive

            gene_tf_signals = []
            for tf_name, bw_handle in bigwig_handles.items():
                if bw_handle is None:
                    # If bigwig file failed to open, use zeros or NaNs
                    # Using NaNs is better for indicating missing data explicitly
                    tf_signal = np.full(promoter_length, np.nan)
                else:
                    try:
                        # Extract signal values for the promoter region
                        # pyBigWig.values returns a list of floats
                        signal_values = bw_handle.values(chrom, promoter_start_0based, promoter_end_0based_exclusive)
                        if signal_values is None: # values() can return None if region is invalid
                             tf_signal = np.full(promoter_length, np.nan)
                        else:
                             tf_signal = np.array(signal_values)

                        # Ensure the extracted signal has the expected length
                        if len(tf_signal) != promoter_length:
                            print(f"Warning: Extracted signal length for {gene_id} ({chrom}:{promoter_start_1based}-{promoter_end_1based}) and TF {tf_name} is {len(tf_signal)}, expected {promoter_length}. Filling with NaN.")
                            tf_signal = np.full(promoter_length, np.nan) # Fill with NaN if length is wrong

                        # DAP-seq signals are typically unstranded, but if strand matters for interpretation later,
                        # we might need to reverse the signal array for genes on the '-' strand.
                        # The plan says "signal is usually considered irrespective of gene strand for TF binding".
                        # So, we don't reverse the signal array based on gene strand here.

                    except Exception as e:
                        print(f"Error extracting signal for gene {gene_id} ({chrom}:{promoter_start_1based}-{promoter_end_1based}) and TF {tf_name}: {e}. Filling with NaN.")
                        tf_signal = np.full(promoter_length, np.nan) # Fill with NaN on error

                gene_tf_signals.append(tf_signal)

            # Stack signals for this gene into a matrix (num_tfs x promoter_length)
            tf_binding_data[gene_id] = np.vstack(gene_tf_signals)

        print("Signal extraction complete.")

    finally:
        # Close all bigwig handles
        for tf_name, bw_handle in bigwig_handles.items():
            if bw_handle is not None:
                bw_handle.close()
                # print(f"Closed bigWig file handle for {tf_name}")

    return tf_binding_data

def save_tf_binding_data(tf_binding_data, output_dir):
    """
    Saves extracted TF binding data for each gene to separate files.
    Using .npy format for efficiency.
    """
    print(f"Saving TF binding data to {output_dir}")
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"Created output directory: {output_dir}")

    for gene_id, signal_matrix in tf_binding_data.items():
        output_path = os.path.join(output_dir, f"{gene_id}_tf_binding.npy")
        try:
            np.save(output_path, signal_matrix)
            # print(f"Saved data for {gene_id}") # Optional: print for each gene
        except Exception as e:
            print(f"Error saving data for gene {gene_id} to {output_path}: {e}. Skipping save for this gene.")

    print("Saving complete.")


if __name__ == "__main__":
    # Step 1: Load promoter regions (assuming it contains coordinates now)
    # *** DEPENDENCY: promoter_regions.tsv needs to be updated by the previous script
    # to include chromosome, start, end, and strand columns. ***
    # For now, we'll load the existing file and acknowledge the missing coordinate info.
    # A real run would require the updated file or a different coordinate source.
    promoter_df = load_promoter_regions(PROMOTER_REGIONS_FILE)

    if promoter_df is not None and not promoter_df.empty:
        # *** RESOLVE COORDINATE DEPENDENCY HERE ***
        # Need to get coordinates for each gene_id in promoter_df.
        # Option A: Modify promoter_extraction.py to save a more detailed file (recommended).
        # Option B: Reload/re-parse GFF3 here (less efficient).
        # Option C: Load a pre-saved gene_info dictionary (requires saving it in previous script).

        # For now, let's simulate having coordinates by adding dummy columns.
        # This is ONLY for the script to be syntactically runnable.
        # In a real workflow, this needs proper data flow from promoter_extraction.py
        print("Adding dummy coordinate columns for demonstration. REPLACE WITH REAL DATA LOADING.")
        # Example dummy data - REPLACE WITH REAL DATA
        dummy_coords = {
            "AT1G01010": ("chr1", 3631, 6131, "+"),
            "AT1G01020": ("chr1", 6700, 9200, "-"),
            # Add more dummy data or load from a file
        }
        # Create new columns in the DataFrame
        promoter_df[['chromosome', 'start', 'end', 'strand']] = promoter_df['gene_id'].apply(
            lambda x: pd.Series(dummy_coords.get(x, (None, None, None, None)))
        )
        # Filter out genes for which we couldn't get dummy coordinates
        promoter_df = promoter_df.dropna(subset=['chromosome'])
        print(f"Proceeding with {len(promoter_df)} genes with available dummy coordinates.")
        # *** END OF COORDINATE DEPENDENCY RESOLUTION SIMULATION ***


        # Step 2: Extract TF binding signals
        # Pass the DataFrame (now with dummy coords) and other necessary info
        tf_binding_data = extract_tf_binding_signals(promoter_df, DAPSEQ_BIGWIG_DIR, TF_BIGWIG_FILES)

        # Step 3: Save extracted data
        if tf_binding_data:
            save_tf_binding_data(tf_binding_data, OUTPUT_DIR)
        else:
            print("No TF binding data extracted. Output directory not created/populated.")
    else:
        print("Could not load promoter regions or file is empty. Skipping TF binding extraction.")