# Module 2: "TF Vocabulary" Feature Engineering

## 1. Objective

This module is responsible for one of the most innovative aspects of the project: transforming the continuous, high-resolution TF binding signals into a sequence of abstract features representing a "TF vocabulary". This step is crucial for reducing dimensionality and providing the transformer model with a more meaningful, structured input that captures local combinatorial binding patterns.

## 2. Key Responsibilities

-   Ingest the normalized TF binding profiles generated by Module 1.
-   Implement a sliding window mechanism to segment the promoter regions.
-   For each window, aggregate the binding signals of all TFs into a single summary vector.
-   Generate the final feature set where each promoter is represented as a sequence of these summary vectors.

## 3. Detailed Implementation Steps

### Step 3.1: Load Normalized Data

-   **Input:** The directory of `.npy` files containing the normalized TF binding signal matrices from Module 1. Each file represents a gene and contains a matrix of size `(Number of TFs x 2501)`.
-   **Process:** Write a data loader that can efficiently read these `.npy` files.

### Step 3.2: Implement the Sliding Window Mechanism

-   **Rationale:** We need to analyze local regions of the promoter to identify combinatorial TF binding. The research plan specifies a 50bp window size.
-   **Process:**
    1.  For each gene's normalized TF binding matrix, define **50bp sliding windows**.
    2.  A **stride** must be chosen for the sliding window. This determines the degree of overlap. A smaller stride creates a longer sequence for the transformer but captures more fine-grained positional shifts.
        -   **Recommendation:** Start with a stride of **25bp**. This creates overlapping windows.
        -   For a 2501bp promoter, a 50bp window with a 25bp stride will result in `floor((2501 - 50) / 25) + 1 = 99` windows per promoter.
    3.  This process will segment the `(Number of TFs x 2501)` matrix into a list of 99 sub-matrices, each of size `(Number of TFs x 50)`.

### Step 3.3: Create Window Summary Vectors

-   **Rationale:** We need to convert the `(Number of TFs x 50)` signal matrix for each window into a single, fixed-size vector that summarizes the TF activity within that window.
-   **Process:**
    1.  For each 50bp window's sub-matrix:
    2.  For each TF (i.e., each row in the sub-matrix), calculate an aggregate statistic over the 50bp.
        -   **Recommendation:** Start by calculating the **mean signal** for each TF within the window. This is robust and captures the general binding level.
        -   Alternatives to consider for future experiments include using the **max signal** (to capture peak binding) or the **sum of signals**.
    3.  The result for each window will be a single vector of length `~300` (one mean value per TF). This is the "TF summary vector" for that window.

### Step 3.4: Generate Final Promoter Representation

-   **Process:**
    1.  After processing all windows for a single promoter, you will have a sequence of 99 "TF summary vectors".
    2.  Combine these vectors into a single matrix of size `(Number of Windows x Number of TFs)`, which for the recommended parameters will be `(99 x ~300)`.
    3.  This matrix is the final, feature-engineered representation for one gene's promoter.
-   **Output:** A new set of `.npy` files, one for each gene, containing the `(99 x ~300)` "TF vocabulary" sequence matrix. This data is the direct input for the Siamese transformer model.

## 4. Recommended Libraries

-   **`NumPy`**: For all numerical and matrix operations.
-   **`scikit-learn`**: May be useful for preprocessing steps if any further scaling of the summary vectors is desired.
-   **`multiprocessing` / `joblib`**: This task is highly parallelizable per gene. Use these libraries to significantly speed up the feature generation process.

## 5. Success Criteria

This module is complete when all normalized promoter profiles have been converted into the "TF vocabulary" sequence format. The output should be a clean, well-documented set of feature files ready for model training. The code should be efficient and capable of processing all genes in a reasonable amount of time.